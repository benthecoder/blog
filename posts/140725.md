---
title: 'goodfire'
tags: 'journal'
date: 'Jul 14, 2025'
---

listend to a [podcast](https://www.youtube.com/watch?v=lDTEFogB_Us) on [goodfire.ai](https://www.goodfire.ai/). a few good resources on mechanistic interpretability

## Key Research Papers

- [Tracing the thoughts of a large language model](https://www.anthropic.com/research/tracing-thoughts-language-model) (Anthropic)
- [On the Biology of a Large Language Model](https://transformer-circuits.pub/2025/attribution-graphs/biology.html)
- [Zoom In: An Introduction to Circuits](https://distill.pub/2020/circuits/zoom-in/)
- [Toy Models of Superposition](https://transformer-circuits.pub/2022/toy_model/index.html)
- [Towards Monosemanticity: Decomposing Language Models With Dictionary Learning](https://transformer-circuits.pub/2023/monosemantic-features)
- [Stage-Wise Model Diffing](https://transformer-circuits.pub/2024/model-diffing/index.html)
- [Mapping the Latent Space of Llama 3.3 70B](https://www.goodfire.ai/papers/mapping-latent-spaces-llama)
- [Attribution-based parameter decomposition](https://www.lesswrong.com/posts/EPefYWjuHNcNH4C7E/attribution-based-parameter-decomposition) (LessWrong)

## Blogs and Guides

- [An Extremely Opinionated Annotated List of My Favourite Mechanistic Interpretability Papers](https://www.alignmentforum.org/posts/NfFST5Mio7BCAQHPA/an-extremely-opinionated-annotated-list-of-my-favourite-1) (AI Alignment Forum)
- [Mechanistic interpretability](https://en.wikipedia.org/wiki/Mechanistic_interpretability) (Wikipedia)
- [Emergent Misalignment: Narrow Finetuning can produce Broadly Misaligned LLMs](https://www.emergent-misalignment.com/)
- [Under the Hood of a Reasoning Model](https://www.goodfire.ai/blog/under-the-hood-of-a-reasoning-model) (Goodfire AI)
- [Language models can explain neurons in language models](https://openai.com/index/language-models-can-explain-neurons-in-language-models/) (OpenAI)
- [Interpreting Evo 2](https://www.goodfire.ai/blog/interpreting-evo-2) (Goodfire AI)
- [The Urgency of Interpretability](https://www.darioamodei.com/post/the-urgency-of-interpretability) (Dario Amodei)

## Tools and Applications

- [Paint with Ember](https://paint.goodfire.ai/)
- [Painting With Concepts Using Diffusion Model Latents](https://www.goodfire.ai/blog/painting-with-concepts)

## Additional Resources

- [Sparse Autoencoder](https://web.stanford.edu/class/cs294a/sparseAutoencoder.pdf) (Stanford)
- [Apollo Research](https://www.apolloresearch.ai/)
